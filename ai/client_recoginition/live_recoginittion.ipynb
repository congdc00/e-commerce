{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# I. Thư viện"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from all_lib import *"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# II. Chuẩn bị"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Gọi GPU"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "data_path = '../../data/face_id'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Tải dữ liệu"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "embeddings= torch.load(data_path + '/facelist.pth')\n",
    "names = np.load(data_path + '/username.npy')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Kích thước đầu vào lấy từ webcam"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "frame_size =  (640, 480)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# III Chuẩn hóa"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Model MTCNN để tách khuôn mặt"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "mtcnn = MTCNN(thresholds= [0.7, 0.7, 0.8] ,keep_all=True, device = device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Các hàm chuẩn hóa"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def standardization(img_tensor_tmp):\n",
    "    normalize = (img_tensor_tmp -127.5)/128\n",
    "    return normalize"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def trans(img):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        fixed_image_standardization\n",
    "    ])\n",
    "    return transform(img)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# IV. Main"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Khởi tạo model InceptionResnetV1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "InceptionResnetV1(\n  (conv2d_1a): BasicConv2d(\n    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    (relu): ReLU()\n  )\n  (conv2d_2a): BasicConv2d(\n    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    (relu): ReLU()\n  )\n  (conv2d_2b): BasicConv2d(\n    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    (relu): ReLU()\n  )\n  (maxpool_3a): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (conv2d_3b): BasicConv2d(\n    (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    (relu): ReLU()\n  )\n  (conv2d_4a): BasicConv2d(\n    (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    (relu): ReLU()\n  )\n  (conv2d_4b): BasicConv2d(\n    (conv): Conv2d(192, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n    (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    (relu): ReLU()\n  )\n  (repeat_1): Sequential(\n    (0): Block35(\n      (branch0): BasicConv2d(\n        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n      (branch1): Sequential(\n        (0): BasicConv2d(\n          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (1): BasicConv2d(\n          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n      )\n      (branch2): Sequential(\n        (0): BasicConv2d(\n          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (1): BasicConv2d(\n          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (2): BasicConv2d(\n          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n      )\n      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n      (relu): ReLU()\n    )\n    (1): Block35(\n      (branch0): BasicConv2d(\n        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n      (branch1): Sequential(\n        (0): BasicConv2d(\n          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (1): BasicConv2d(\n          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n      )\n      (branch2): Sequential(\n        (0): BasicConv2d(\n          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (1): BasicConv2d(\n          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (2): BasicConv2d(\n          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n      )\n      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n      (relu): ReLU()\n    )\n    (2): Block35(\n      (branch0): BasicConv2d(\n        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n      (branch1): Sequential(\n        (0): BasicConv2d(\n          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (1): BasicConv2d(\n          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n      )\n      (branch2): Sequential(\n        (0): BasicConv2d(\n          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (1): BasicConv2d(\n          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (2): BasicConv2d(\n          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n      )\n      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n      (relu): ReLU()\n    )\n    (3): Block35(\n      (branch0): BasicConv2d(\n        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n      (branch1): Sequential(\n        (0): BasicConv2d(\n          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (1): BasicConv2d(\n          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n      )\n      (branch2): Sequential(\n        (0): BasicConv2d(\n          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (1): BasicConv2d(\n          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (2): BasicConv2d(\n          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n      )\n      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n      (relu): ReLU()\n    )\n    (4): Block35(\n      (branch0): BasicConv2d(\n        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n      (branch1): Sequential(\n        (0): BasicConv2d(\n          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (1): BasicConv2d(\n          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n      )\n      (branch2): Sequential(\n        (0): BasicConv2d(\n          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (1): BasicConv2d(\n          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (2): BasicConv2d(\n          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n      )\n      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n      (relu): ReLU()\n    )\n  )\n  (mixed_6a): Mixed_6a(\n    (branch0): BasicConv2d(\n      (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU()\n    )\n    (branch1): Sequential(\n      (0): BasicConv2d(\n        (conv): Conv2d(256, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n      (1): BasicConv2d(\n        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n      (2): BasicConv2d(\n        (conv): Conv2d(192, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n    )\n    (branch2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (repeat_2): Sequential(\n    (0): Block17(\n      (branch0): BasicConv2d(\n        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n      (branch1): Sequential(\n        (0): BasicConv2d(\n          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (1): BasicConv2d(\n          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (2): BasicConv2d(\n          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n      )\n      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n      (relu): ReLU()\n    )\n    (1): Block17(\n      (branch0): BasicConv2d(\n        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n      (branch1): Sequential(\n        (0): BasicConv2d(\n          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (1): BasicConv2d(\n          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (2): BasicConv2d(\n          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n      )\n      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n      (relu): ReLU()\n    )\n    (2): Block17(\n      (branch0): BasicConv2d(\n        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n      (branch1): Sequential(\n        (0): BasicConv2d(\n          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (1): BasicConv2d(\n          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (2): BasicConv2d(\n          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n      )\n      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n      (relu): ReLU()\n    )\n    (3): Block17(\n      (branch0): BasicConv2d(\n        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n      (branch1): Sequential(\n        (0): BasicConv2d(\n          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (1): BasicConv2d(\n          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (2): BasicConv2d(\n          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n      )\n      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n      (relu): ReLU()\n    )\n    (4): Block17(\n      (branch0): BasicConv2d(\n        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n      (branch1): Sequential(\n        (0): BasicConv2d(\n          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (1): BasicConv2d(\n          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (2): BasicConv2d(\n          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n      )\n      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n      (relu): ReLU()\n    )\n    (5): Block17(\n      (branch0): BasicConv2d(\n        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n      (branch1): Sequential(\n        (0): BasicConv2d(\n          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (1): BasicConv2d(\n          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (2): BasicConv2d(\n          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n      )\n      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n      (relu): ReLU()\n    )\n    (6): Block17(\n      (branch0): BasicConv2d(\n        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n      (branch1): Sequential(\n        (0): BasicConv2d(\n          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (1): BasicConv2d(\n          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (2): BasicConv2d(\n          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n      )\n      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n      (relu): ReLU()\n    )\n    (7): Block17(\n      (branch0): BasicConv2d(\n        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n      (branch1): Sequential(\n        (0): BasicConv2d(\n          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (1): BasicConv2d(\n          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (2): BasicConv2d(\n          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n      )\n      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n      (relu): ReLU()\n    )\n    (8): Block17(\n      (branch0): BasicConv2d(\n        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n      (branch1): Sequential(\n        (0): BasicConv2d(\n          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (1): BasicConv2d(\n          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (2): BasicConv2d(\n          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n      )\n      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n      (relu): ReLU()\n    )\n    (9): Block17(\n      (branch0): BasicConv2d(\n        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n      (branch1): Sequential(\n        (0): BasicConv2d(\n          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (1): BasicConv2d(\n          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (2): BasicConv2d(\n          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n      )\n      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n      (relu): ReLU()\n    )\n  )\n  (mixed_7a): Mixed_7a(\n    (branch0): Sequential(\n      (0): BasicConv2d(\n        (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n      (1): BasicConv2d(\n        (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n    )\n    (branch1): Sequential(\n      (0): BasicConv2d(\n        (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n      (1): BasicConv2d(\n        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n    )\n    (branch2): Sequential(\n      (0): BasicConv2d(\n        (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n      (1): BasicConv2d(\n        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n      (2): BasicConv2d(\n        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n    )\n    (branch3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (repeat_3): Sequential(\n    (0): Block8(\n      (branch0): BasicConv2d(\n        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n      (branch1): Sequential(\n        (0): BasicConv2d(\n          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (1): BasicConv2d(\n          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (2): BasicConv2d(\n          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n      )\n      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n      (relu): ReLU()\n    )\n    (1): Block8(\n      (branch0): BasicConv2d(\n        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n      (branch1): Sequential(\n        (0): BasicConv2d(\n          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (1): BasicConv2d(\n          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (2): BasicConv2d(\n          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n      )\n      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n      (relu): ReLU()\n    )\n    (2): Block8(\n      (branch0): BasicConv2d(\n        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n      (branch1): Sequential(\n        (0): BasicConv2d(\n          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (1): BasicConv2d(\n          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (2): BasicConv2d(\n          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n      )\n      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n      (relu): ReLU()\n    )\n    (3): Block8(\n      (branch0): BasicConv2d(\n        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n      (branch1): Sequential(\n        (0): BasicConv2d(\n          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (1): BasicConv2d(\n          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (2): BasicConv2d(\n          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n      )\n      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n      (relu): ReLU()\n    )\n    (4): Block8(\n      (branch0): BasicConv2d(\n        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n      (branch1): Sequential(\n        (0): BasicConv2d(\n          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (1): BasicConv2d(\n          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (2): BasicConv2d(\n          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n      )\n      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n      (relu): ReLU()\n    )\n  )\n  (block8): Block8(\n    (branch0): BasicConv2d(\n      (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU()\n    )\n    (branch1): Sequential(\n      (0): BasicConv2d(\n        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n      (1): BasicConv2d(\n        (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n      (2): BasicConv2d(\n        (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n    )\n    (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (avgpool_1a): AdaptiveAvgPool2d(output_size=1)\n  (dropout): Dropout(p=0.6, inplace=False)\n  (last_linear): Linear(in_features=1792, out_features=512, bias=False)\n  (last_bn): BatchNorm1d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (logits): Linear(in_features=512, out_features=10575, bias=True)\n)"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = InceptionResnetV1(\n",
    "    classify=False,\n",
    "    pretrained=\"casia-webface\"\n",
    ").to(device)\n",
    "\n",
    "model.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Lấy camera"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_cap = cv2.VideoCapture(0)\n",
    "video_cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "video_cap.set(cv2.CAP_PROP_FRAME_HEIGHT,480)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Funtion"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "extract_face: Trích xuất khuôn mặt từ các bounding box\n",
    "Thông số:\n",
    "- margin: Tương đương với margin khi capture_face ( để là 20)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "def extract_face(box, img, margin=20):\n",
    "    face_size = 160\n",
    "    img_size = frame_size\n",
    "    margin = [\n",
    "        margin * (box[2] - box[0]) / (face_size - margin),\n",
    "        margin * (box[3] - box[1]) / (face_size - margin),\n",
    "    ] #tạo margin bao quanh box cũ\n",
    "    box = [\n",
    "        int(max(box[0] - margin[0] / 2, 0)),\n",
    "        int(max(box[1] - margin[1] / 2, 0)),\n",
    "        int(min(box[2] + margin[0] / 2, img_size[0])),\n",
    "        int(min(box[3] + margin[1] / 2, img_size[1])),\n",
    "    ]\n",
    "    img = img[box[1]:box[3], box[0]:box[2]]\n",
    "    face = cv2.resize(img,(face_size, face_size), interpolation=cv2.INTER_AREA)\n",
    "    face = Image.fromarray(face)\n",
    "    return face"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Kết xuất embedding cho từng ảnh mặt - thứ đã được extract từ hàm extract_face() ở trên"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "def inference(model, face, local_embeds, threshold = 3):\n",
    "    #local: [n,512] voi n la so nguoi trong faceslist\n",
    "    embeds = []\n",
    "    # print(trans(face).unsqueeze(0).shape)\n",
    "    embeds.append(model(trans(face).to(device).unsqueeze(0)))\n",
    "    detect_embeds = torch.cat(embeds) #[1,512]\n",
    "    # print(detect_embeds.shape)\n",
    "    #[1,512,1]                                      [1,512,n]\n",
    "    norm_diff = detect_embeds.unsqueeze(-1) - torch.transpose(local_embeds, 0, 1).unsqueeze(0)\n",
    "    # print(norm_diff)\n",
    "    norm_score = torch.sum(torch.pow(norm_diff, 2), dim=1) #(1,n), moi cot la tong khoang cach euclide so vs embed moi\n",
    "\n",
    "    min_dist, embed_idx = torch.min(norm_score, dim = 1)\n",
    "    print(min_dist*power, names[embed_idx])\n",
    "    # print(min_dist.shape)\n",
    "    if min_dist*power > threshold:\n",
    "        return -1, -1\n",
    "    else:\n",
    "        return embed_idx, min_dist.double()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "main"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "mpDraw = mp.solutions.drawing_utils\n",
    "mpPose = mp.solutions.pose\n",
    "pose = mpPose.Pose()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "x = [1200, 980, 800, 680, 580, 520, 448, 412, 372, 348, 320, 300, 280, 268, 248, 236, 228]\n",
    "y = [20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 95, 100]\n",
    "coff = np.polyfit(x, y, 2)  # y = Ax^2 + Bx + C\n",
    "A, B, C = coff"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "prev_frame_time = 0\n",
    "new_frame_time = 0\n",
    "power = pow(10, 6)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0881], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.4184], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([3.5386], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([6.4706], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([4.1976], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([3.1036], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([4.0615], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.8199], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.5444], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.3796], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([2.0705], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([4.8083], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([5.2985], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([2.0792], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([2.3002], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.5210], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.5122], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.0901], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.1579], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.1647], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.1866], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.1718], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.1724], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.1442], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.1652], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.2113], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.1585], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.1326], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.1603], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.1881], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.1754], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.1728], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.1720], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.1831], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.2663], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.2503], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.2550], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.2754], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.4661], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.4705], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.6271], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.7305], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.7761], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.7847], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.7977], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.7468], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.6484], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.6382], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.5475], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.5024], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.4833], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.5586], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.5594], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.5009], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.5009], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.5682], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.5243], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.4996], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.4675], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.5570], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.5275], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.5318], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.5421], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.5139], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.5300], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.6545], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.6491], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.6852], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.6640], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.6746], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.6811], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.6587], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.6538], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.6888], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.6605], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.6688], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.6760], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.6752], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.6922], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.6936], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.7122], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.6626], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.6931], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.6960], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.6588], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.6879], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.6697], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.6911], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.6591], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.6724], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.6478], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.6682], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.6959], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.6802], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.6772], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.6687], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.6440], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.6721], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.6620], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.6864], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.6665], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.6771], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.6832], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.6797], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.6872], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.7059], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.6760], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.6839], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.6909], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.6939], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.7012], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.6905], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.6881], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.7013], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.6789], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.6906], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.7032], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.6844], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.6612], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.6518], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.7331], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.7279], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.7359], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.7429], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.7554], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.7480], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.7678], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.7637], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.7572], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.7408], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.7140], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.7365], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.7158], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.7646], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.7407], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.7495], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.7060], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.7863], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.7812], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.7439], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.7607], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.7507], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.7335], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.7461], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.7766], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.7352], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.7467], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.7613], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.7671], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.7515], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.7388], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.7608], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.7683], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.7209], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.7384], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.7168], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.7292], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.6542], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.6131], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.6729], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.3061], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.2127], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.2573], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.1994], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.2293], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.1937], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.2570], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.2467], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.2211], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.1617], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.1742], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.1589], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.1237], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.1642], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.1487], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.0783], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.1577], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.2472], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.0490], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.0433], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.0967], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.4447], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.4812], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.3884], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.3495], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.5643], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.8440], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.5980], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.7224], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.9476], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.9819], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1866], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1897], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.2134], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.2044], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1983], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1469], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1697], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.2205], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1712], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.2132], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.1470], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1735], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1325], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1434], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1615], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1480], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1965], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1631], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1287], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1614], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1437], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1849], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1786], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1754], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1599], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1087], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.0403], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.8520], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.9582], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.8200], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.5583], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.7346], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([3.1331], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.7581], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.7172], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.6212], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.5627], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.6921], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.5597], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.6749], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.6131], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.6197], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.6002], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.5626], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.6335], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.6113], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.6008], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.5436], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.7454], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.7950], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.9096], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.8956], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.9341], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.9078], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.9369], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.9548], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.9029], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.9099], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.9122], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.9252], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.0058], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.0078], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.0134], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.9935], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.0101], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.9945], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.9922], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.9963], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.0012], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.0081], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.0256], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.9883], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.9500], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.9517], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.9614], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.9546], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.9742], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.9428], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.9748], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.9704], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.9865], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.9862], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.7579], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.7453], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.7211], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.6868], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.6594], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.7757], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.8539], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.8487], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.8125], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.8496], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.8766], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.9095], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.8673], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.7899], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.8343], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.7873], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.8350], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.8011], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.8077], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.7987], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.8207], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.8273], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.8252], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.8571], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.7928], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.7765], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.8219], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.8206], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.8400], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.8343], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.7458], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.7127], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.6925], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.6687], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.7049], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.6882], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.6552], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.6381], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.6458], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.6149], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.7168], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.6137], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.6349], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.6564], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.6333], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.6403], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.6470], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.6863], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.6363], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.6645], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.6105], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.5833], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.6598], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.6712], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.6288], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([6.9155], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.0968], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.1578], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.1398], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.2722], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.1823], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.3314], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.3360], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.1886], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.1981], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.1762], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.2529], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.1007], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.1138], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.1525], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.2444], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.1699], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.0858], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.1478], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.1283], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.2509], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.1153], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.1025], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.1630], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.1343], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.1194], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.1736], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.2813], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.0520], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.2492], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.3599], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.2009], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.2671], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.3567], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.2461], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.3696], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.3256], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.3030], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.3313], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.1813], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.3106], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.2953], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.3812], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.3317], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.2305], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.2127], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.3120], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.2425], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.2908], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.2439], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.4364], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.2570], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.3247], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.3265], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.2612], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.1963], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.2648], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.1990], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.2286], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.2660], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.1654], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.2141], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.3057], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.2983], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.3393], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.1952], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.2746], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.2972], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.2577], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.1818], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.4034], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.3116], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.4226], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.2763], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.3095], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.2905], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.2919], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.3681], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.3294], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.4436], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.4523], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.3869], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.3335], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.1858], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.4341], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.3715], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.4201], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.4026], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.3354], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.2503], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.3000], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.3358], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.2762], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.2988], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.3327], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.2500], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.4289], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.2631], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.2619], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.2439], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.2815], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.1348], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.1738], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.2743], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.7313], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.2157], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.3835], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.4753], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.5064], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.5494], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.7957], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.8652], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.0594], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1755], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.2096], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.2323], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1430], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1977], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1614], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1468], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1673], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.9182], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1941], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.2002], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.9590], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.9297], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.2435], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.2272], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1824], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.2015], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1801], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1916], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.2039], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.2528], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1993], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1321], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1473], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1556], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.0762], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1438], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.9648], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.0750], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1435], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.0678], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1441], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1834], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1896], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1256], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1987], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1902], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1280], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1718], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1577], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1533], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1419], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1559], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1285], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1493], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1461], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1204], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1258], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1732], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1515], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1203], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.2151], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1952], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1491], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.2164], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1359], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1269], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1704], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1727], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1698], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1674], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1756], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1767], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1948], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1721], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.2048], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.2048], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1592], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.2531], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1341], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1690], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1730], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1379], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1237], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1366], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1541], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1954], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1617], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1817], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1748], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.2139], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.2320], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1185], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1692], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.2050], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1743], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.2041], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1859], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1597], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1801], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1689], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1572], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.2148], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1702], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.2303], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1527], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.2184], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1563], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1961], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.2030], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.2178], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1863], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1975], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1801], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.2043], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1597], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1831], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1821], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.2147], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1879], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([1.1362], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.5411], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.6432], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.5997], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.6616], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.4122], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.4687], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.4583], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.4752], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.4683], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.4755], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.4183], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.4405], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.4559], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.6247], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.5485], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.5158], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.5246], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.5888], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.7223], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.4476], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.3648], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.4324], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.3557], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.5304], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.7814], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.5670], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.4905], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.4497], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.3884], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.2997], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.2014], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.1230], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.1267], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.0898], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.0568], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.3349], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.1242], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.0833], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.2795], device='cuda:0', grad_fn=<MulBackward0>) Cong\n",
      "tensor([0.3340], device='cuda:0', grad_fn=<MulBackward0>) Cong\n"
     ]
    }
   ],
   "source": [
    "while video_cap.isOpened():\n",
    "    isSuccess, frame = video_cap.read()\n",
    "    imgRGB= cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = pose.process(imgRGB)\n",
    "    cvzone.putTextRect(frame,'Trang thai', (2,40), colorR=(14,201,255))\n",
    "    #text_status = 'Dang Tim'\n",
    "    if results.pose_landmarks:\n",
    "        mpDraw.draw_landmarks(frame,results.pose_landmarks,mpPose.POSE_CONNECTIONS )\n",
    "        for index ,dot in enumerate(results.pose_landmarks.landmark):\n",
    "            if(index == 11):\n",
    "                hight ,weight,c=frame.shape\n",
    "                center_x1, center_y1 =int(dot.x*weight),int(dot.y*hight)\n",
    "                cv2.circle(frame,(center_x1,center_y1),5,(0,0,255),cv2.FILLED)\n",
    "\n",
    "            if(index == 12):\n",
    "                hight ,weight,c=frame.shape\n",
    "                center_x2, center_y2 =int(dot.x*weight),int(dot.y*hight)\n",
    "                cv2.circle(frame,(center_x2,center_y2),5,(0,0,255),cv2.FILLED)\n",
    "        distance = int(math.sqrt((center_y2 - center_y1) ** 2 + (center_x2 - center_x1) ** 2))\n",
    "        distanceCM = A * distance ** 2 + B * distance + C\n",
    "        cvzone.putTextRect(frame, f'Khoang cach:{int(distanceCM)} ', (1,95), colorR=(14,201,255))\n",
    "        # nhan dien khach hang\n",
    "        boxes, _ = mtcnn.detect(frame)\n",
    "        if boxes is not None:\n",
    "            for box in boxes:\n",
    "                bbox = list(map(int,box.tolist()))\n",
    "                face = extract_face(bbox, frame)\n",
    "                idx, score = inference(model, face, embeddings)\n",
    "                if idx != -1:\n",
    "                    frame = cv2.rectangle(frame, (bbox[0],bbox[1]), (bbox[2],bbox[3]), (255,201,14), 4)\n",
    "                    score = torch.Tensor.cpu(score[0]).detach().numpy()*power\n",
    "                    cvzone.putTextRect(frame, names[idx] + '_{:.2f}'.format(score), (bbox[0],bbox[1]), colorR=(255,201,14))\n",
    "                    cvzone.putTextRect(frame, 'Da tim thay' , (290,40), colorR=(0,255,0))\n",
    "                    cvzone.putTextRect(frame, 'Dung' , (1,480), colorR=(14,201,255))\n",
    "                else:\n",
    "                    frame = cv2.rectangle(frame, (bbox[0],bbox[1]), (bbox[2],bbox[3]), (255,201,14), 4)\n",
    "                    cvzone.putTextRect(frame, 'Unknown', (bbox[0],bbox[1]), colorR=(255,201,14))\n",
    "                    cvzone.putTextRect(frame, 'Nham nguoi' , (290,40), colorR=(0,0,255))\n",
    "                    cvzone.putTextRect(frame, 'Lui' , (1,480), colorR=(14,201,255))\n",
    "        else:\n",
    "            cvzone.putTextRect(frame, 'Nhan dang' , (290,40), colorR=(0,0,255))\n",
    "            cvzone.putTextRect(frame, 'Tien' , (1,480), colorR=(14,201,255))\n",
    "    else:\n",
    "        cvzone.putTextRect(frame, 'Dang tim' , (290,40), colorR=(0,0,255))\n",
    "\n",
    "\n",
    "\n",
    "    cv2.imshow('Face Recognition', frame)\n",
    "    if cv2.waitKey(1)&0xFF == 27:\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "video_cap.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}